% Chapter 2: METHODS

\chapter{Methods} % Main chapter title

\label{methods} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%%----------------------------------------------------------------------------------------
%
%% Define some commands to keep the formatting separated from the content 
%\newcommand{\keyword}[1]{\textbf{#1}}
%\newcommand{\tabhead}[1]{\textbf{#1}}
%\newcommand{\code}[1]{\texttt{#1}}
%\newcommand{\file}[1]{\texttt{\bfseries#1}}
%\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------
The purpose of this methods section is to give an overview on, first, the data that was used to develop the software tool and how the data were collected, second, image processing basics, and third, what programming languages, definitions and methods chosen when developing the tool. This will help the reader to replicate, understand and modify the methods and source code of the tool. 

%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------
\section{Data set}

Our data set consisted of high-throughput time-lapse images of Arabidopsis roots taken by a standard Raspberry Pi V2 camera from 5 experiments with 5-6 roots each containing between 32 and 36 images over a period of at least 5 hours, ie every 10 minutes a photo was taken. The images were named by the date and time they were taken. 

It should be noted that these images had already been collected in a previous project and are not subject but only the basis of the work presented here. 

However, to better understand the nature of the data, we will give a high-level explanation of the experiment setup that was used to collect these data.


%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------
\section{Experiment setup}

[SEE SLIDES, THESIS]

[INSERT FIGURE: ESSAY FOR ROOT ELECTROTROPISM]

[INSERT FIGURE: PHENOMENOLOGY OF ROOT ELECTROTROPISM]


%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------
\section{Image processing}

Having these images as a basis, the nature of this work was mainly of image processing nature.

Image processing pools together a lot of different domains including physics (optics), signal processing and pattern recognition/ Machine Learning (ML) to ultimately feed computer to understand how to interpret images and make decisions based on them. 

The idea behind image processing is to extract information from an image information in a form that is suitable for computer processing [INSERT REFERENCE HERE]. 

Figure [INSERT REFERENCE HERE] shows fundamental steps in image processing, that served as a guideline for the presented work.


%combines optics and signal processing and is often used in computer vision.
%\begin{enumerate}
%	\item Image aquisition
%	\item Image preprocessing 
%	\item Image segmentation
%	\item Image representation and description -- dep on image that you are studying
%	\item Image understanding
%	\item Results (output)
%\end{enumerate}

[INSERT FLOWCHART FIGURE HERE, adapted from....]


%----------------------------------------------------------------------------------------
\subsection{Digital images}

In image processing, we operate on digital (discrete) images.
An image refers to a 2D light intesity function \( f(x,y) \), where \( (x,y) \) denote spatial coordinates and the value of \( f \) at any point \( (x,y) \) is proportional to the brightness or gray levels of the image at that point [INSERT REFERENCE HERE].
A digital image is an image \( f(x,y)  \) that has been discretised both in spatial coordinates and brightness, ie we

\begin{itemize}
	\item Sample the 2D space on a regular grid
	\item Quantise each sample, ie round to nearest integer.
\end{itemize}

What we get is an image represented as a matrix of integer values; the elements of such a digital array are called image elements or pixels.

%If our samples are \( \Delta \) apart, we can write this as:
%\[
%f(x,y) = Quantize{f(\Delta x, \Delta y)}
%\]
%The image can now be represented as a matrix of integer values:

[INSERT EXAMPLE PICTURE HERE]


%----------------------------------------------------------------------------------------
\subsection{On spatial resolution, gray levels and coloured images}

The storage and preprocessing requirements increase rapidly with the spatial resolution and the number of gray levels. 
For instance, a 256 gray-scale image of size 256 \( \times \) 256 occupies 64K bytes of memory. Figure [INSERT REFERENCE HERE] shows images of different spatial resolution. 

[INSERT FIGURE: Images with decreasing spatial resolution, taken from .....]

Also, an insufficient number of gray levels in smooth areas of a digital image may result in false contouring, see figure [INSERT REFERENCE HERE].

[INSERT FIGURE: Images of different gray-level quantisation]


Since we deal with coloured images, we chose the RGB colour model which is an additative colour model in which red, green and blue light are added together in various ways to reproduce a broad spectrum of colours [INSERT REFERENCE HERE].


%----------------------------------------------------------------------------------------
\subsection{Image processing operations}

An image processing operation typically defines a new image \( g \) in terms of an existing image \( f \).
We can 
\begin{itemize}
	\item transform the range of \( f \)
	\[ 
	g(x, y) = t(f(x,y)) 
	\]
	\item transform the domain of \( f \)
	\[
	g(x,y) = f(t_{x}(x,y), t_{y}(x,y)).
	\]
\end{itemize}

%IMAGE PROCESSING OPERATIONS USED IN THIS WORK INCLUDE: 

From an image processing point of view, we performed point as well as local operations.

A point operation is a function that is performed on each single pixel of an image, independent of all the other pixels in that image [INSERT REFERENCE HERE]. These include operations like inversing, changing the brightness or contrast of an image, changing the gamma of an image, binarising an image and logical operations. 

Local operations, on the other hand, compute the new value of each single pixel with a neighbourhood around it [INSERT REFERENCE HERE]. %They can be divided in two groups, linear and nonlinear filters.
They include filters which are operations that converts a source image to a result image by applying some kind of tranformation, be it of linear or nonlinear nature [INSERT REFERENCE HERE]. There are more than 134 different filter functions in the MATLAB Image Processing toolbox that can be applied with different arguments and sensitivity thresholds. Filters used in our work include the 2D median filtering \textit{medfilt2} or the 2D adaptive noise-removal filtering \textit{wiener2}.

%A a filter is an operation, which converts a source image via some kind of transformation to a result image [INSERT REFERENCE HERE]. 

% FOR VIIVA: Another possibility for the subdivision of local operations is the division in low-pass and high-pass filters. Low-pass filters are used to inhibit noise and small details on images, whereas high-pass filters are used to emphasize edges."
% http://www.tlmtracker.tu-bs.de/index.php/Image_processing_operations#Threshold


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%----TO DELETE---
%\subsection{Key stages in digital image processing}
%
%[INSERT FLOW CHART HERE]
%
%	Problem Domain -- here plant morphology 
%\begin{itemize}
%	\item Image Aquisition
%	\item Image Enhancement -- contrasting images so human eye can best see things, manipulate values of pixels so you can best caracterise and structure them |
%	\item Morphological Processing -- growing and thinning of pixels, eg fingerpringt medical operations
%	\item Image Segmentation -- separating parts of the image such as features and object you want to look at, distribution of pixel values |
%	\item Representation \& Description -- based on quantised space that you're working in. What's realised in that digital output? Two ways to describe features being observed in that pixel space. Inverting etc
%	\item Object Recognition -- see example iris data set. cluster to identify different objects.
%	\item [Computer \& Machine Vision] -- feeds into computer vision and ML
%\end{itemize}
%	[Robotics \& AI], [Deep Learning]
%	
%	feature space that you're working in on top of your labels.
%	put in our own bias and how we train model.
%	
%	A lot of noise in the image makes it grainy. We can apply interpolation, ie smoothing the image based on its nn. bi-cubic interpolation.  Smoothes some of the details as well as a side effect, but especially the noise. -- important for edge detection later
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------
\section{\textit{MATLAB} as a programming language}

As a language we chose \textit{Matlab} as it is very popular in academic circles for image/ data processing given the number of built-in functions, including well documented image processing toolbox (\textit{MATLAB Image Processing Toolbox} [INSERT REFERENCE HERE]).
%with a very good documentation. 
% GOES TO DISCUSSION/ FUTURE WORK:
%Alternative languages that were considered were \textit{Python} and \textit{Julia}. Another recommended language is \textit{OpenCV} as it is very fast and well documented. Other non-open source software such as \textit{ImageJ}, a Java based image processing program, and \textit{Avizo} which is a general-purpose commercial software application for scientific and industrial data visualisation and analysis with a nice GUI, could not be investigated further in this work. 


%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------
\section{Pre-processing: Getting the root's skeleton}

The goal of the preprocessing step was to extract the skeleton, ie the coordinates of the pixels that represent the root on the image.
This task turned out to be highly challenging on noisy image data and can be regarded as the actual achievement of the presented work. The highly elaborate pipeline of the preprocessing step can be found in chapter [INSERT REFERENCE HERE].


% TO DELETE
%For the
%The initial problem of coming up with a "good" definition by comparing different angle and curvature definition shifted. The focus was now on the pre-processing, the extracting the skeleton. 
%However, we will still present some possible definitions of angles and curvature, also not implemented in the current version of the tool.


%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------
\section{Computing the angle}

Once the skeleton has been extracted, one can compute the curvature and the angle of the root tip. 
In fact, we only need to segment the bit of the root that is close to the tip including the bending point, ie the point with highest local curvature, not the entire root. This will help to discard lots of noise caused by tubes and other objects at the upper part of the root, see section [INSERT REFERENCE] for example of images.

Various definitions of angles associated to the root tip had been considered; however, in order to make the angles comparable to the so far manually computed angles we chose an emulation of the manual computation of the angle in our final implementation. 

% GOES TO DISCUSSION/ FUTURE WORK
%Approaches like computing the Gaussian mean curvature, definitions of different, possibly more robust methods of computing and angle %are mentioned here, but has 
%have not been incorporated in our final tool. 


The angle \( \Theta \) we want to compute is the angle between the line through the point of the highest local (Gaussian) curvature and the root tip and a line parallel to the electric field (EF).  

Figure [INSERT REFERENCE HERE] illustrates the angle \( \Theta \) that is computed. 

[INSERT FIGURE: HOW THE ANGLE IN RESPONSE TO THE ELECTRIC FIELD IS CALCULATED: The angle \( \Theta \) represents the angle between the line through the tip of the root and the point of highest local curvature and a line parallel to the EF.]


Once these two lines are correctly defined, provided the point of highest local curvature is unique, it is straight forward to compute angle \( Theta \).


%There are other ways such as finding vectors on the lines and using their dot products. However, we can use simple, basic trigonometric methods as shown in figure [INSERT REFERENCE HERE].
%
%We would then compute the angles of the two lines to the x-axis  in radians mode by 
%\[
%\pi - | \tan^{-1}(\frac{x(2) - x(1)}{y(2) - y(1)}) - \tan^{-1}(\frac{z(2) - z(1)}{y(2) - y(1)}) |
%\]
%or 
%\[
%180^{\circ} - | \tan^{-1}(\frac{x(2) - x(1)}{y(2) - y(1)}) - \tan^{-1}(\frac{z(2) - z(1)}{y(2) - y(1)}) |
%\]
%if we wanted it in degrees mode.
%
%The single steps are shown in figure ....
%[PSEUDOCODE]
%\begin{enumerate}
%	\item Find the slope of each line.
%	\item Find the inclination of each line using \( \alpha = \tan^{-1} m \), where  \( \alpha \) is the angle of inclination, \( m \) is the slope.
%	\item Take the difference of these two angles.
%	\item Handle the case where this difference is not an acute, ie less than 90 degrees, angle. If we get a negative angle, we take its absolute value. We want to find an acute angle, so if we calculated an obtuse angle, oe greater than 90 degrees, we just subtract the value from pi radians or 180 degrees to get the acute values.
%\end{enumerate}


%We refer to figure [INSERT REFERENCE HERE] to how the angle was computed in previous approaches. 


Let \( v_{1} \) be the line through the tip of the root and the point of highest local curvature and \( v_{2} \) a line parallel to the EF. 
We can compute angle \( \Theta \)  by using simple trigonometric methods 

\begin{equation} \label{angle1}
\Theta_{1}  = \cos^{-1}\frac{( v_{1} \cdot v_{2}) }{ | v_{1} | \cdot | v_{2} |}
\end{equation}
or equivalently
\begin{equation} \label{angle2}
\Theta_{2} = \tan^{-1}( v_{1}, v_{2}) \times \frac{180}{\pi}
\end{equation}
depending on the signedness of \( v_{1} \) and \( v_{2} \). Assuming the tip of the root only bends positively, ie towards the cathode (the negative pole of the EF) in our experiment setup, and \( v_{2} \) is not positive nor negative, the sign of \( \Theta \) only depends on \( v_{1} \). If the root tip crosses the line that is completely aligned with, ie parallel to, the EF (where \( \Theta \) takes the value 0), \( \Theta \) becomes negative as \( v_{1} \) will become negative. 


%----------------------------------------------------------------------------------------
\subsection{Computing the curvature of the root tip}

In order to detect the point of highest local curvature, we need to compute the curvature at each point in the skeleton. 




%APPROACH 2
% This function calculates the curvature of a 2D line. It first fits 
% polygons to the points. Then calculates the analytical curvature from
% the polygons
%
%  k = LineCurvature(Vertices,Lines)
% 
% inputs,
%   Vertices : A M x 2 list of line points.
%   (optional)
%   Lines : A N x 2 list of line pieces, by indices of the vertices
%         (if not set assume Lines=[1 2; 2 3 ; ... ; M-1 M])
%
% outputs,
%   k : M x 1 Curvature values
%
% If no line-indices, assume a x(1) connected with x(2), x(3) with x(4)


% Fit polygons to the vertices 
% x=a(3)*t^2 + a(2)*t + a(1) 
% y=b(3)*t^2 + b(2)*t + b(1) 
% we know the x,y of every vertex and set t=0 for the vertices, and
% t=Ta for left vertices, and t=Tb for right vertices,  


%APPROACH 1
% Use skeleton/bwboundaries to get a list of the (x,y) boundary coordinates. 
% Run around that border taking a section of the curve, say 9 elements, and fit 
% a polynomial to it. Knowing the derivative of the curve model I used, and 
% the coefficients polyfit() gave me, I can get the curvature at each point. 
% [Optional: Then I run around the list of (x,y) edge coordinates using a marker color 
% that corresponds to the curvature.]

% A large radius of curvature means a "flat" part of the curve while a small radius 
% of curvature means "pointy" parts of the curve.
% Whether it is positive or negative just says which side of the curve it is bending to. 
% I could just take the absolute value of the curvature if I do not care which 
% side it bends toward; however, we do care as the root bends positively (clockwise).


%OLD APPROACHES:

%CURVATURE VIA TRIANGLE -- 3 POINTS 

%ANGLE BETWEEN TWO POINTS USING SCALAR PRODUCT
 
%CURVATURE USING FORMULA FROM PAPER ROBERT ISRAEL



%%----------------------------------------------------------------------------------------
%\subsection{Using the position of the tip of the root -- more in detail}
%
%INSERT FIGURE OF WHAT ANGLE WE CALCULATE AND WHAT IS THE ANGLE OF INTEREST. 
%USER-FRIENDLY: EASILY SWITCH BETWEEN THE TWO OF THEM.
%
%We find the angle between the two lines (point of highest mean curvture OR manually click point of highest curvature and tip and point of highest mean curvature and equally distant point/ pixel on root).


%
%%----------------------------------------------------------------------------------------
%\subsection{Using the angle of the tangents to the points that are x points/pixels away from the point of highest local curvature}
%
%%\subsection{INSERT VARIOUS OTHER IDEAS OF ANGLE COMPUTATION -- even if not implemented}
