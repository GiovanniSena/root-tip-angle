% Chapter 3: RESULTS

\chapter{Results} % Main chapter title

\label{results} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%%----------------------------------------------------------------------------------------
%
%% Define some commands to keep the formatting separated from the content 
%\newcommand{\keyword}[1]{\textbf{#1}}
%\newcommand{\tabhead}[1]{\textbf{#1}}
%\newcommand{\code}[1]{\texttt{#1}}
%\newcommand{\file}[1]{\texttt{\bfseries#1}}
%\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------

PROVIDE A HIGH-LEVEL REVIEW, NOT LOTS OF NUMBERS

REPRODUCABILITY OF WORK, ie make sure reader could redo it

%%----------------------------------------------------------------------------------------
%%----------------------------------------------------------------------------------------

The following section of this report will briefly explain the tool from a technical perspective, but more importantly  %and show how to use it in practice. %Additionally, we present an example of the tool in use.
we will present some highlights of the tool that sets it apart from other tools and we will guide the user through one example to illustrate how the tool is used in practice.

Additionally, we will show some validation of the tool by comparing the angle computed by our tool to the one computed manually on one time-series image data set of one Arabidopsis root. 

The code is open-source and publicly available on [INSERT GITHUB REFERENCE HERE]; all previous versions including log files can be found on [INSERT GITHUB REFERENCE HERE].
[EMPHASISE THIS: MAKE RESEARCH TRANSPARENT]


%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------
\section{Key features} %SHOW HOW ELEABORATE TOOL IS

Figure [INSERT REFERENCE HERE: PIPELINE FROM GUI] explains the key components of this image-analysis software tool to address the problem of highly noisy electrotropism consumer camera images of Arabidopsis roots and a standardised way of computing the angle for the curved root tip. 

This tool takes the form of a MATLAB program and subprograms with a graphical user interface (GUI) on top of it.

%----------------------------------------------------------------------------------------
\subsection{Graphical User Interface}
To make the program more user-friendly, we developed a graphical user interface (GUI). Pop-up windows will guide the user through the process (see [INSERT REFERENCE HERE]); a separate manual is not necessary as the steps are very intuitive and straight-forward.
There are various benefits of the GUI such as
\begin{itemize}
	\item Visualising the process including the pipeline
	\item Easy user interaction with mouse clicking
	\item Flexibility, eg the user can go back at each step without rerunning the whole script from the beginning
	\item Pop-up windows and mouseover functions on buttons that guide the user through the process and explain the steps
	\item Error messages if user does not enter right values.
\end{itemize}


%----------------------------------------------------------------------------------------
\subsection{Discerning root from background}

Gamma correction (imadjust)


%----------------------------------------------------------------------------------------
\subsection{Handling user's mistakes}

When we take the user's input, eg choosing samples along the root, we correct for small mistakes by taking an neighbourhood (3 \( \times \)) average around the pixel. 
%followed by adaptive thresholding.
This means the user does not have to take special care when choosing the points as long as it is in the approximate region of the root.


\subsection{User interaction and optional steps}
The software tool was created in a ways that it is easy to interact with for a future user. 
We implemented several optional steps that only need to be performed if the user thinks it is necessary. This on the other hand saves time in the preprocessing but on the other hand also ensures that tricky roots can be tackled by various optional steps in order to extract a skeleton. 


%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------
\section{Workflow of root skeletonisation -- explained on GUI}

The pipeline that has been developed for the preprocessing step of extracting the skeleton is displayed in figure [INSERT REFERENCE HERE] ans can be viewed at the bottom of the GUI, see figure [INSERT REFERENCE HERE].
In the appendix [INSERT REFERENCE HERE] we present the tool on one example image guides the reader through the pipeline and can serve as a manual for future users.

[INSERT FIGURE OF DIFFERENT STEPS (SUBFIGURES) THAT ARE THEN REFERRED TO IN THE TEXT INDIVIDUALLY]


%%%%%
%
%1) Treating the image 
%- multiplying to enhance contrast
%- gamma correction
%- adaptive thresholding
%- inverting image
%
%2) User draws a window around root of interest, samples 5-10 points of chosen root.
%Using the mean value and standard deviation of the pixel intensity of these points a thresholding range is found. Say [mu-3sigma,mu+3sigma]. 
%(Using the same threshold for all the images in the experiment was not successful as the noise patterns of the images vary too much.)
%
%
%3) Treating the cropped image using different filters
%
%Approach 1: Colour separation filtering 
%- based on RGB values of points
%- gray scales image
%
%Approach 2: Brightness filtering (intensity-based approach)
%- enhances brightness 
%- eliminates too bright spots
%
%4) SKELETONIZATION
%- unified approach (approach 1+2)
%
%5) Optional: additional cleaning
%- iteratively removing bigger and bigger connected objects (in steps of 30 pixels)



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%-----WORK FROM HERE----%%%%%%%%%%%


%----------------------------------------------------------------------------------------
\subsection{Loading a file}

%----------------------------------------------------------------------------------------
\subsection{Zooming in}

and cropping


%----------------------------------------------------------------------------------------
\subsection{Choosing points}


%----------------------------------------------------------------------------------------
\subsection{Processing the image}

Two approaches:
1.
Converted into gray channel images.
2.


%----------------------------------------------------------------------------------------
\subsection{Optional image cropping}

Additional cropping of the root ultimately solves the problem of getting rid of any artificial branches caused by noise close to the tip of the root.
Also, the cropping does not have to be very accurate.


%----------------------------------------------------------------------------------------
\subsection{Extracting the skeleton}

%----------------------------------------------------------------------------------------
\subsection{Optional skeleton cropping}


%----------------------------------------------------------------------------------------
\subsection{Optional foreign object removal}

Other than that, the user can perform iterative cleaning that gradually gets rid of those artificial branches (most of the times) as well; one has to be careful not to "loose" the root completely, but the user can undo the last cleaning step. 

%----------------------------------------------------------------------------------------
\subsection{Optional tip forcing}


%----------------------------------------------------------------------------------------
\subsection{Final preparation}


%----------------------------------------------------------------------------------------
\subsection{Angle computation}


%0) Convert the image from rgb to gray scale (matlab: rgb2gray) (3-tensor to matrix)
%
%intensify the matrix \arrowvert distinguish roots for user
%highlight window \arrowvert help user where approximately roots are 
%
%1. The user will select a region of interest on the image so only roots appear. This window can be used over the whole experiment (as camera doesn’t move) ///TODO: or better to define window for each root?
%
%2. The user then clicks on some points over the roots (I'd say at least 7, preferably 10). Using the mean value and standard deviation of the pixel intensity of these points a thresholding range is found. Say [mu-2sigma,mu+2sigma]. 
%Initially trying to use the same threshold for all the images in the experiment, maybe this will do the job already…
%
%3. After segmenting the images, the binary images need to postprocessed so we get rid of the bright spots and noise, eg by removing any object that has fewer than 1000 pixels (matlab: bwareaopen enough?). Then any holes that might appear in the roots need to be filled (matlab: imfill) 
%
%4. Hopefully obtaining the skeleton version of the binary image (matlab: bwmorph).
%
%5. Label each individual object in the image so they can later be processed independently (matlab: bwconncomp). 
%6. For each root we then get the list of point belonging to the tip (upper x- and y-values) and we compute the curvature (eg on a 3-point polygonal chain)


%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------
\section{Components of the GUI}

With the development of the GUI for more user-friendliness, we split our source code of the tool based on functionality, ie we create separate functions or modules that we then connect to several objects in the GUI. This process, also known as \textit{modularity} in software engineering, has various benefits for developing and maintaining the application: The code is less cluttered but more structured and readable and just by reading the main functions which calls all other subfunctions you get a general overview and understanding of what the code does. Also, it reduces redundancy in the main code if the codes get split up into smaller subfunctions and helps debugging. Speaking variables also add to a better understanding of the code.

%MODULARITY — main code is not as cluttered, things that are called again and again, migrate it. several functions use same code. 
%REDUCE REDUNDANCY
%MORE READIBLE, CLEARER, MORE STRUCTURED, DON’T GET LOST IF YOU ONLY READ MAIN CODE, GENERAL THIGNS THAT HAPPEN.
%SPEAKING VARIABLES. 

%Beyond that, provided the interface, ie input and output of each modules, is well defined modularity allows a team of developers to work on the functionality of one single module without involving other modules. They are not distracted by functionalities that are not relevant, known as information hiding in software engineering. Also, it helps to keep the code short and simple and focused one core functionality. It is also useful to identify bugs early on in the development process.

Here, it allowed us to not only handle front-end and back-end but also the different steps in the pipeline separately: 

Every function representing one specific step in the pipeline or objects accessed by various functions is encoded in the back-end which is not visible and relevant for the future user. These modules are connected via callbacks to different objects in the GUI which represent the front-end.

%Back-end as well as front-end needs maintaining. 
%The line between the two of them is often blurry.
%
%Front-end: involved with what the user sees, including design. 


Table [INSERT REFERENCE HERE] gives an overview of the different components and modules our software tool \textit{RootSkel} consists of. It has been developed over a cycle of various iterations, together with an exemplary future user. 
The current version of the package can be downloaded from %https://github.com/burfel/root-tip-angle/tree/master/src/Root_image_GUI_v1_5 and will be maintained on [INSERT GIOVANNIS GITHUB HERE].


%image_process.m
%* extracts the cropped image 
%* extracts the colours from the sample pixels, averages it with a certain neighbourhood
%* takes a brightness range, an average of the three filters used 
%* approach 1: using input from the user to estimate the range of the root colours
%* initial colour filtering based on the RGB values of the selected points
%* subsequent gray filtering
%* RGB level difference based filtering
%* …….
%* approach 2: using brightness filter (intensity based)
%* Idea: We carefully enhance the brightness and then get rid of too bright spots.
%* gray scaling
%* creating a filtering mask according to the brightness rank


Even though most of image processing work is empirical, ie based on trial and error and educated guesses on the given data set, we try to explain why certain features were necessary to implement. %this explanations are marked in italics.
The pipeline can be seen in the at the bottom of the GUI in figure [INSERT REFERENCE HERE].

[INCLUDE IN GRAPHIC IF EXCEED WORD COUNT]

%1. Open file
%2. Zoom in
%3. Choose Points
%4. Process image
%5. Crop image (optional): 
%6. Get skeleton
%7. Crop skeleton (optional): It allows the user to crop a region around the skeleton by hand to definitely remove things outside the region of interest. The user can redo the cropping in case she is not satisfied. 
%8. Foreign object removal (optional): It allows the user to remove objects, ie if the skeleton contains undesired branches. The user can undo the last cleaning step in case the root gets removed in the last step, to not start the entire process again. 
%9. Force tip (optional)
%10. Final preparation
%
%The bar on the left shows various other buttons that allow the user to perform other functions:
%* In the upper part: 
%* Save variables
%* Save figures: select the cropped image or the skeleton; both are greyed out as longs as objects have not been created
%* Load variables
%* Load figure: choose one of the radio buttons either on the left or on the right
%* In the middle part: 
%* Show skeleton; greyed out as long as the skeleton has not been created
%* Clear figure: choose one of the radio buttons either on the left or on the right
%* The bottom part to compute and display the angle:
%* Using user’s point
%* Using curvature

The GUI includes helpful text along the pipeline as well as pop up windows including instructions or warnings in case the user does not follow them. 

In the appendix [INSERT REFERENCE HERE] we guide the user through the different steps of the pipeline and present one example each; this can serve as a manual for users even though the steps are rather self-explanatory by just using the GUI. Also, having a GUI rather than a script with pop-up-windows not only makes the tool more visually attractive but it one can also repeat a step without restarting the whole process or script again. This all adds to the user-friendliness.

%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------
\section{Validation: Comparing the automated calculated angles with the manually calculated angles}

As a preview of validation we performed our webtool on [INSERT HERE] roots over a time of [INSERT HERE] hours. We compared both the automatically computed angles with the previously computed manual angle. As a second validation step we also compared the angles to the computed angles with user input.

Figure [INSERT HERE] shows the comparison of the angle of interest \( Theta \), both of the manual as well as the automatically computed angle at [INSERT HERE] times steps over a period of [INSERT HERE] time.

The variance of the angle pairs is shown in figure [INSERT HERE]. Performing a t-test [OR CHI-SQUARED TEST] we can conclude that the improvement of the angle computation accuracy is significant. Approximately [INSERT HERE] \% due to human error can be eliminated.
%Looking at the variance of the angle pairs and performing a t-Test, we can conclude that by our tool we can minimise the human error by [INSERT HERE]\%. 

Once more angles have been compared, more confident statistics can be obtained. 

[INSERT FIGURE HERE]

We can observe that the angle \( \Theta \) converges continuously towards 0.

