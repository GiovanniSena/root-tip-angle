% Chapter 3: RESULTS

\chapter{Results} % Main chapter title

\label{results} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%%----------------------------------------------------------------------------------------
%
%% Define some commands to keep the formatting separated from the content 
%\newcommand{\keyword}[1]{\textbf{#1}}
%\newcommand{\tabhead}[1]{\textbf{#1}}
%\newcommand{\code}[1]{\texttt{#1}}
%\newcommand{\file}[1]{\texttt{\bfseries#1}}
%\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------

PROVIDE A HIGH-LEVEL REVIEW, NOT LOTS OF NUMBERS

REPRODUCABILITY OF WORK, ie make sure reader could redo it

%%----------------------------------------------------------------------------------------
%%----------------------------------------------------------------------------------------

The following section of this report will briefly explain the tool from a technical perspective, but more importantly  %and show how to use it in practice. %Additionally, we present an example of the tool in use.
we will present some highlights of the tool that sets it apart from other tools and we will guide the user through one example to illustrate how the tool is used in practice.

Additionally, we will show some validation of the tool by comparing the angle computed by our tool to the one computed manually on one time-series image data set of one Arabidopsis root. 

The code is open-source and publicly available on [INSERT GITHUB REFERENCE HERE]; all previous versions including log files can be found on [INSERT GITHUB REFERENCE HERE].
[EMPHASISE THIS: MAKE RESEARCH TRANSPARENT]


%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------
\section{Key features} %SHOW HOW ELEABORATE TOOL IS

Figure [INSERT REFERENCE HERE: PIPELINE FROM GUI] explains the key components of this image-analysis software tool to address the problem of highly noisy electrotropism consumer camera images of Arabidopsis roots and a standardised way of computing the angle for the curved root tip. 

This tool takes the form of a MATLAB program and subprograms with a graphical user interface (GUI) on top of it.

%----------------------------------------------------------------------------------------
\subsection{Graphical User Interface}
To make the program more user-friendly, we developed a graphical user interface (GUI). Pop-up windows will guide the user through the process (see [INSERT REFERENCE HERE]); a separate manual is not necessary as the steps are very intuitive and straight-forward.
There are various benefits of the GUI such as
\begin{itemize}
	\item Visualising the process including the pipeline
	\item Easy user interaction with mouse clicking
	\item Flexibility, eg the user can go back at each step without rerunning the whole script from the beginning
	\item Pop-up windows and mouseover functions on buttons that guide the user through the process and explain the steps
	\item Error messages if user does not enter right values.
\end{itemize}


%----------------------------------------------------------------------------------------
\subsection{Discerning root from background}

Gamma correction (imadjust)


%----------------------------------------------------------------------------------------
\subsection{Handling user's mistakes}

When we take the user's input, eg choosing samples along the root, we correct for small mistakes by taking an neighbourhood (3 \( \times \)) average around the pixel. 
%followed by adaptive thresholding.
This means the user does not have to take special care when choosing the points as long as it is in the approximate region of the root.


\subsection{User interaction and optional steps}
The software tool was created in a ways that it is easy to interact with for a future user. 
We implemented several optional steps that only need to be performed if the user thinks it is necessary. This on the other hand saves time in the preprocessing but on the other hand also ensures that tricky roots can be tackled by various optional steps in order to extract a skeleton. 


%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------
\section{Workflow of root skeletonisation -- explained on GUI}

The pipeline that has been developed for the preprocessing step of extracting the skeleton is displayed in figure [INSERT REFERENCE HERE] ans can be viewed at the bottom of the GUI, see figure [INSERT REFERENCE HERE].
In the appendix [INSERT REFERENCE HERE] we present the tool on one example image guides the reader through the pipeline and can serve as a manual for future users.

[INSERT FIGURE OF DIFFERENT STEPS (SUBFIGURES) THAT ARE THEN REFERRED TO IN THE TEXT INDIVIDUALLY]


%%%%%
%
%1) Treating the image 
%- multiplying to enhance contrast
%- gamma correction
%- adaptive thresholding
%- inverting image
%
%2) User draws a window around root of interest, samples 5-10 points of chosen root.
%Using the mean value and standard deviation of the pixel intensity of these points a thresholding range is found. Say [mu-3sigma,mu+3sigma]. 
%(Using the same threshold for all the images in the experiment was not successful as the noise patterns of the images vary too much.)
%
%
%3) Treating the cropped image using different filters
%
%Approach 1: Colour separation filtering 
%- based on RGB values of points
%- gray scales image
%
%Approach 2: Brightness filtering (intensity-based approach)
%- enhances brightness 
%- eliminates too bright spots
%
%4) SKELETONIZATION
%- unified approach (approach 1+2)
%
%5) Optional: additional cleaning
%- iteratively removing bigger and bigger connected objects (in steps of 30 pixels)



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%-----WORK FROM HERE----%%%%%%%%%%%
%----------------------------------------------------------------------------------------
\subsection{Optional additional cleaning}

Other than that, the user can perform iterative cleaning that gradually gets rid of those artificial branches (most of the times) as well; one has to be careful not to "loose" the root completely, but the user can undo the last cleaning step. 

%----------------------------------------------------------------------------------------
\subsection{Optional additional cropping of root}

Additional cropping of the root ultimately solves the problem of getting rid of any artificial branches caused by noise close to the tip of the root.
Also, the cropping does not have to be very accurate.



%0) Convert the image from rgb to gray scale (matlab: rgb2gray) (3-tensor to matrix)
%
%intensify the matrix \arrowvert distinguish roots for user
%highlight window \arrowvert help user where approximately roots are 
%
%1. The user will select a region of interest on the image so only roots appear. This window can be used over the whole experiment (as camera doesn’t move) ///TODO: or better to define window for each root?
%
%2. The user then clicks on some points over the roots (I'd say at least 7, preferably 10). Using the mean value and standard deviation of the pixel intensity of these points a thresholding range is found. Say [mu-2sigma,mu+2sigma]. 
%Initially trying to use the same threshold for all the images in the experiment, maybe this will do the job already…
%
%3. After segmenting the images, the binary images need to postprocessed so we get rid of the bright spots and noise, eg by removing any object that has fewer than 1000 pixels (matlab: bwareaopen enough?). Then any holes that might appear in the roots need to be filled (matlab: imfill) 
%
%4. Hopefully obtaining the skeleton version of the binary image (matlab: bwmorph).
%
%5. Label each individual object in the image so they can later be processed independently (matlab: bwconncomp). 
%6. For each root we then get the list of point belonging to the tip (upper x- and y-values) and we compute the curvature (eg on a 3-point polygonal chain)


Two approaches:
1.
Converted into gray channel images.
2.


%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------


\section{Components of the GUI}

With the development of the GUI for more user-friendliness, we split our source code of the tool based on functionality, ie we create separate functions or modules that we then connect to several objects in the GUI. This process, also known as \textit{modularity} in software engineering, has various benefits for developing and maintaining the application: The code is less cluttered but more structured and readable and just by reading the main functions which calls all other subfunctions you get a general overview and understanding of what the code does. Also, it reduces redundancy in the main code if the codes get split up into smaller subfunctions and helps debugging. Speaking variables also add to a better understanding of the code.

%MODULARITY — main code is not as cluttered, things that are called again and again, migrate it. several functions use same code. 
%REDUCE REDUNDANCY
%MORE READIBLE, CLEARER, MORE STRUCTURED, DON’T GET LOST IF YOU ONLY READ MAIN CODE, GENERAL THIGNS THAT HAPPEN.
%SPEAKING VARIABLES. 

%Beyond that, provided the interface, ie input and output of each modules, is well defined modularity allows a team of developers to work on the functionality of one single module without involving other modules. They are not distracted by functionalities that are not relevant, known as information hiding in software engineering. Also, it helps to keep the code short and simple and focused one core functionality. It is also useful to identify bugs early on in the development process.

Here, it allowed us to not only handle front-end and back-end but also the different steps in the pipeline separately: 

Every function representing one specific step in the pipeline or objects accessed by various functions is encoded in the back-end which is not visible and relevant for the future user. These modules are connected via callbacks to different objects in the GUI which represent the front-end.

%Back-end as well as front-end needs maintaining. 
%The line between the two of them is often blurry.
%
%Front-end: involved with what the user sees, including design. 


Table [INSERT REFERENCE HERE] gives an overview of the different components and modules our software tool \textit{RootSkel} consists of. It has been developed over a cycle of various iterations, together with an exemplary future user. 
The current version of the package can be downloaded from %https://github.com/burfel/root-tip-angle/tree/master/src/Root_image_GUI_v1_5 and will be maintained on [INSERT GIOVANNIS GITHUB HERE].

1. Root_image_GUI.m
The main file that calls all subfiles and the GUI handler?,
added warning and message boxes

2. Log files: Lox.txt and Old_Versions_Log.txt 
Log files documenting all changes including dates since the last version (Log.txt) as well as previous versions (Old_Versions_Log.txt) so changes can be undone and future developers can build upon the existing version. A shorter versions of previous log files including bug fixes can be found in CurrentVersion.txt

3. Functions 
Folder containing the following 18 functions with a short description of each:

var_saver.m
* creates a variable varnames which contains the names of the relevant variables (skelmatR, skelmatR_simp, max_curv_point, savename). It then pulls them from the base workspace and lets the user save them in a .mat file. skelmatR or skelmatR_simp include the skeleton of the root (their x and y coordinates), max_curv_point includes the user’s input for the possible turning point or an empty set, savename includes the name of the image (date and hour) and the number of the roots which is used for names of figures, first column in csv file and default of var_saver.m
skelmatR is redundant.

var_loader.m
* allows the user to load the .mat files including the relevant objects from the workspace
* contains the enabling of appropriate angle calculation buttons; buttons are disabled to avoid bugs and errors (eg angle computation on nothing should not work)

skel_crop.m
* contains the optional free hand cropping of the skeleton

skel_clean.m
* loops on optional additional cleaning, ie bigger and bigger objects are removed, until user is satisfied

savename_crea.m
* saves the label of the root or root number the user chooses in order to keep track of which root is analysed
* combines the label with the name of the file and saves it as a folder where the variables (see above) would go


root_skel.m: 
* Different steps of filtering and cleaning until we get root skeleton????? ACTUAL CODE?
The main functions from the Matlab Image Processing Toolbox used here were different versions and combinations of imfill, fibremetric, wiener2, imbinarise, bwareaopen, medfilt2, bwmorph that we identified worked best on our given data set. For a detailed description of the functions we refer to [INSERT REFERENCE HERE].
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%          AD APPROACH 1: the colour-based approach                           %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Trying to use fibermetric to get rid of the annoying thorns without
% sacrificing root. Hopefully, it will make the rest of the section become
% better. First imfill though
* imfill
* fibremetric — to get rid of branches without sacrifising the root, with specific sensitivity, enhances tubular structure
* imfill — fill in holes
* wiener2 noise filtering function (after the binarisation)
doing a set of binarising, getting rid of isolated points, filling stuff and them skeletonising and other methods.
* turn neighbourhood of the tip to white and hope it helps
* whitening of the tip’s neighbourhood
* bwareopen
* medfilt2 function tro try and improve the process to exclude closed loops and such
* imfill — fill in holes in binarised image
* bwmorph — clean isolated pixels until image series converges (does not change much, sort of safety measure)
* bwareaopen — get rid of isolated non-root structures (< 35 pixels), but be careful since we can destroy roots

* bwmorph — extract skeleton
* imfill — fill in holes bc skeletonisation creates holes sometimes
* bwmorph— close small gaps
* bwareaopen — get rid of isolates non-root structures (< 35 pixels), but be careful that not destroy roots

* bwmorph — destroy small branches (be carful in picture2 destroys roots? fix it.)

* bwareaopen — get rid of isolates non-root structures (< 35 pixels), but be careful that not destroy roots

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%          AD APPROACH 2: The intensity method skeleton                       %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% I shall now apply the new refined process in the hopes of it working
% smoothly.
* imfill — see comments above
* fibermetric
* imfill
* wiener2
* whitening of tip’s neighbourhoos
* imbinarise
* bwareaopen
* medfilt2

* imfill — holes
* bwmorph — skel
* imfill — holes
* bwmorph — bridge

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%          COMBINING APPROACH 1 + 2: A unified front                          %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The avarage binarized:
unified_skeleton=0.5*(color_skeleton+brightness_skeleton);
unified_skeleton(unified_skeleton>0)=1;
unified_skeleton=bwmorph(unified_skeleton,'spur',15) % SUCCESS. we got roots without little branches.


point_get.m
* asks the user for points as long as she does not provide the required number (defined as a number of points between minimum and maximum)
* The user’s input is stored in the strings srcx and srcy are strings with the name of the variable that will receive the data in the base workspace; they tell assignin in which variable in the caller to store the data.


point_choose.m
* collects the necessary points from the user: 5 points  close to the tip, 5 - 10 evenly spaced points on the desired root starting with the tip, the tip of the root
* each step can be redone


THE USER DOES NOT HAVE TO HIT THE EXACT ROOT, WE TAKE AN AVERAGE VALUE WITHIN A CERTAIN NEIGHBOURHOOD.
INCLUDES HOVER UP MESSAGES. 

COLOUR AND INTENSITY FILTERS, GOOD START BUT NOT ENOUGH BC NOISE CAN SAME COLOURS AND INTENSITY.
fails on too images/ getting skeleton is really hard.
noise which skeleton functions mistakes for non-noise
what can really differentiate: shape of root, but didn’t get to work on that.
implementing a shape based filter

image_zoom.m
* inverts the image 
* lets the user zoom in (and zoom out via right click)

image_process.m
* extracts the cropped image 
* extracts the colours from the sample pixels, averages it with a certain neighbourhood
* takes a brightness range, an average of the three filters used 
* approach 1: using input from the user to estimate the range of the root colours
* initial colour filtering based on the RGB values of the selected points
* subsequent gray filtering
* RGB level difference based filtering
* …….
* approach 2: using brightness filter (intensity based)
* Idea: We carefully enhance the brightness and then get rid of too bright spots.
* gray scaling
* creating a filtering mask according to the brightness rank

image_crop.m
* optional free hand cropping

image_choose.m
* allows the user to choose an image
* modifies the image using various filter to help the user discern the root

getAngle.m
* takes the skeleton as input
* computes the curvature and angle of the root tip

force_tip.m
* prompts user to create an open polygon between the edge of the current skeleton and the tip 
* in order to make sure that the tip of the root is definitely included in the skeleton 

final_prep.m
* extracts only the tip of the root and the respective x and y values which are passed on to getAngle.m
* user can choose to select the turning point, ie point with highest local curvature, which can serve as another verification of the computed turning point; it does not have to be exactly on the root as the point in the skeleton that is closest to the chosen point is used

fig_saver.m
* saves the relevant objects upon clicking different buttons

fig_loader.m
* loads respective figures



angle_file.m
* creates a .txt file containing the label of the root (picture name and root number) and the angle
* creates a file with the name 'root_angles.csv' or 'user_assisted' depending on user_flag (see LOG 22.8.18 16:57) and prints the label of the root and the angle; this file can be appended for consecutive angle calculations of the same root in other images




%%%%-------------------------------------------
We will now guide the user through the different steps of the pipeline and present one example each; this can serve as a manual for users even though the steps are rather self-explanatory by just using the GUI. Also, having a GUI rather than a script with pop-up-windows not only makes the tool more visually attractive but it one can also repeat a step without restarting the whole process or script again. This all adds to the user-friendliness.

Even though most of image processing work is empirical, ie based on trial and error and educated guesses on the given data set, we try to explain why certain features were necessary to implement; this explanations are marked in italics.
The pipeline can be seen in the at the bottom of the GUI in figure [INSERT REFERENCE HERE].

[INCLUDE IN GRAPHIC IF EXCEED WORD COUNT]

1. Open file
2. Zoom in
3. Choose Points
4. Process image
5. Crop image (optional): 
6. Get skeleton
7. Crop skeleton (optional): It allows the user to crop a region around the skeleton by hand to definitely remove things outside the region of interest. The user can redo the cropping in case she is not satisfied. 
8. Foreign object removal (optional): It allows the user to remove objects, ie if the skeleton contains undesired branches. The user can undo the last cleaning step in case the root gets removed in the last step, to not start the entire process again. 
9. Force tip
10. Final preparation

The bar on the left shows various other buttons that allow the user to perform other functions:
* In the upper part: 
* Save variables
* Save figures: select the cropped image or the skeleton; both are greyed out as longs as objects have not been created
* Load variables
* Load figure: choose one of the radio buttons either on the left or on the right
* In the middle part: 
* Show skeleton; greyed out as long as the skeleton has not been created
* Clear figure: choose one of the radio buttons either on the left or on the right
* The bottom part to compute and display the angle:
* Using user’s point
* Using curvature

The GUI includes helpful text along the pipeline as well as pop up windows including instructions or warnings in case the user does not follow them. 


%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------
\section{Validation: Comparing the automated calculated angles with the manually calculated angles}

As a preview of validation we performed our webtool on [INSERT HERE] roots over a time of [INSERT HERE] hours. We compared both the automatically computed angles with the previously computed manual angle. As a second validation step we also compared the angles to the computed angles with user input.

Figure [INSERT HERE] shows the comparison of the angle of interest \( Theta \), both of the manual as well as the automatically computed angle at [INSERT HERE] times steps over a period of [INSERT HERE] time.

The variance of the angle pairs is shown in figure [INSERT HERE]. Performing a t-test [OR CHI-SQUARED TEST] we can conclude that the improvement of the angle computation accuracy is significant. Approximately [INSERT HERE] \% due to human error can be eliminated.
%Looking at the variance of the angle pairs and performing a t-Test, we can conclude that by our tool we can minimise the human error by [INSERT HERE]\%. 

Once more angles have been compared, more confident statistics can be obtained. 

[INSERT FIGURE HERE]

We can observe that the angle \( \Theta \) converges continuously towards 0.

