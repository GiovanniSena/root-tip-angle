% Chapter 3: RESULTS

\chapter{Results} % Main chapter title

\label{results} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%%----------------------------------------------------------------------------------------
%
%% Define some commands to keep the formatting separated from the content 
%\newcommand{\keyword}[1]{\textbf{#1}}
%\newcommand{\tabhead}[1]{\textbf{#1}}
%\newcommand{\code}[1]{\texttt{#1}}
%\newcommand{\file}[1]{\texttt{\bfseries#1}}
%\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------

PROVIDE A HIGH-LEVEL REVIEW, NOT LOTS OF NUMBERS

REPRODUCABILITY OF WORK, ie make sure reader could redo it

%%----------------------------------------------------------------------------------------
%%----------------------------------------------------------------------------------------

The following section of this report will briefly explain the tool from a technical perspective, but more importantly  %and show how to use it in practice. %Additionally, we present an example of the tool in use.
we will present some highlights of the tool that sets it apart from other tools and we will guide the user through one example to illustrate how the tool is used in practice.

Additionally, we will show some validation of the tool by comparing the angle computed by our tool to the one computed manually on one time-series image data set of one Arabidopsis root. 

The code is open-source and publicly available on [INSERT GITHUB REFERENCE HERE]; all previous versions including log files can be found on [INSERT GITHUB REFERENCE HERE].
[EMPHASISE THIS: MAKE RESEARCH TRANSPARENT]


%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------
\section{Key features} %SHOW HOW ELEABORATE TOOL IS

Figure [INSERT REFERENCE HERE: PIPELINE FROM GUI] explains the key components of this image-analysis software tool to address the problem of highly noisy electrotropism consumer camera images of Arabidopsis roots and a standardised way of computing the angle for the curved root tip. 

This tool takes the form of a MATLAB program and subprograms with a graphical user interface (GUI) on top of it.

%----------------------------------------------------------------------------------------
\subsection{Graphical User Interface}
To make the program more user-friendly, we developed a graphical user interface (GUI). Pop-up windows will guide the user through the process (see [INSERT REFERENCE HERE]); a separate manual is not necessary as the steps are very intuitive and straight-forward.
There are various benefits of the GUI such as
\begin{itemize}
	\item Visualising the process including the pipeline
	\item Easy user interaction with mouse clicking
	\item Flexibility, eg the user can go back at each step without rerunning the whole script from the beginning
	\item Pop-up windows and mouseover functions on buttons that guide the user through the process and explain the steps
	\item Error messages if user does not enter right values.
\end{itemize}


%----------------------------------------------------------------------------------------
\subsection{Discerning root from background}

Gamma correction (imadjust)


%----------------------------------------------------------------------------------------
\subsection{Handling user's mistakes}

When we take the user's input, eg choosing samples along the root, we correct for small mistakes by taking an neighbourhood (3 \( \times \)) average around the pixel. 
%followed by adaptive thresholding.
This means the user does not have to take special care when choosing the points as long as it is in the approximate region of the root.


\subsection{User interaction and optional steps}
The software tool was created in a ways that it is easy to interact with for a future user. 
We implemented several optional steps that only need to be performed if the user thinks it is necessary. This on the other hand saves time in the preprocessing but on the other hand also ensures that tricky roots can be tackled by various optional steps in order to extract a skeleton. 


%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------
\section{Workflow of root skeletonisation -- explained on GUI}

The pipeline that has been developed for the preprocessing step of extracting the skeleton can be viewed on the bottom of the GUI, see figure [INSERT REFERENCE HERE].
In the following we will present the tool on one example image guides the reader through the pipeline and can serve as a manual for future users.

[INSERT FIGURE OF DIFFERENT STEPS (SUBFIGURES) THAT ARE THEN REFERRED TO IN THE TEXT INDIVISUALLY]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%-----WORK FROM HERE----%%%%%%%%%%%
%----------------------------------------------------------------------------------------
\subsection{Optional additional cleaning}

Other than that, the user can perform iterative cleaning that gradually gets rid of those artificial branches (most of the times) as well; one has to be careful not to "loose" the root completely, but the user can undo the last cleaning step. 

%----------------------------------------------------------------------------------------
\subsection{Optional additional cropping of root}

Additional cropping of the root ultimately solves the problem of getting rid of any artificial branches caused by noise close to the tip of the root.
Also, the cropping does not have to be very accurate.



%0) Convert the image from rgb to gray scale (matlab: rgb2gray) (3-tensor to matrix)
%
%intensify the matrix \arrowvert distinguish roots for user
%highlight window \arrowvert help user where approximately roots are 
%
%1. The user will select a region of interest on the image so only roots appear. This window can be used over the whole experiment (as camera doesn’t move) ///TODO: or better to define window for each root?
%
%2. The user then clicks on some points over the roots (I'd say at least 7, preferably 10). Using the mean value and standard deviation of the pixel intensity of these points a thresholding range is found. Say [mu-2sigma,mu+2sigma]. 
%Initially trying to use the same threshold for all the images in the experiment, maybe this will do the job already…
%
%3. After segmenting the images, the binary images need to postprocessed so we get rid of the bright spots and noise, eg by removing any object that has fewer than 1000 pixels (matlab: bwareaopen enough?). Then any holes that might appear in the roots need to be filled (matlab: imfill) 
%
%4. Hopefully obtaining the skeleton version of the binary image (matlab: bwmorph).
%
%5. Label each individual object in the image so they can later be processed independently (matlab: bwconncomp). 
%6. For each root we then get the list of point belonging to the tip (upper x- and y-values) and we compute the curvature (eg on a 3-point polygonal chain)


Two approaches:
1.
Converted into gray channel images.
2.



%----------------------------------------------------------------------------------------
%----------------------------------------------------------------------------------------
\section{Validation: Comparing the automated calculated angles with the manually calculated angles}

As a preview of validation we performed our webtool on [INSERT HERE] roots over a time of [INSERT HERE] hours. We compared both the automatically computed angles with the previously computed manual angle. As a second validation step we also compared the angles to the computed angles with user input.

Figure [INSERT HERE] shows the comparison of the angle of interest \( Theta \), both of the manual as well as the automatically computed angle at [INSERT HERE] times steps over a period of [INSERT HERE] time.

The variance of the angle pairs is shown in figure [INSERT HERE]. Performing a t-test [OR CHI-SQUARED TEST] we can conclude that the improvement of the angle computation accuracy is significant. Approximately [INSERT HERE] \% due to human error can be eliminated.
%Looking at the variance of the angle pairs and performing a t-Test, we can conclude that by our tool we can minimise the human error by [INSERT HERE]\%. 

Once more angles have been compared, more confident statistics can be obtained. 

[INSERT FIGURE HERE]

We can observe that the angle \( \Theta \) converges continuously towards 0.

